{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-e85f9deeb911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "image_file_path = r\"F:\\papers\\FeaDistribution\\spa\\stego\\0.2\\0001.bmp\"\n",
    "img = io.imread(image_file_path)\n",
    "img = img[:,:,0]\n",
    "[height, width, channel] = np.shape(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_18:0\", shape=(2000, 3000, 1), dtype=int32)\n",
      "Tensor(\"Const_28:0\", shape=(2, 2, 3, 1), dtype=float32)\n",
      "Tensor(\"histogram_fixed_width_21:0\", shape=(21,), dtype=float32)\n",
      "[ 10.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor)\n",
    "new_values = tf.constant([-1.0, 0.0, 1.5, 2.0, 5.0, 15, -1.0, 0.0, 1.5, 2.0, 5.0, 15], shape=[2,2,3,1])\n",
    "print(new_values)\n",
    "output = tf.histogram_fixed_width(values=new_values[],\n",
    "                                  value_range=[0.0, 255.0],\n",
    "                                  nbins=21,\n",
    "                                  dtype=tf.float32)\n",
    "print(output)\n",
    "with tf.Session() as sess:\n",
    "    output_ = sess.run(output)\n",
    "    print(output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can not squeeze dim[0], expected a dimension of 1, got 6 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [6].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[0], expected a dimension of 1, got 6 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [6].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-ddf52ef5df49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy\u001b[1;34m(labels, logits, weights, scope, loss_collection, reduction)\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[1;31m# therefore, expected_rank_diff=1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m     labels, logits, weights = _remove_squeezable_dimensions(\n\u001b[1;32m--> 739\u001b[1;33m         labels, logits, weights, expected_rank_diff=1)\n\u001b[0m\u001b[0;32m    740\u001b[0m     losses = nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n\u001b[0;32m    741\u001b[0m                                                          \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py\u001b[0m in \u001b[0;36m_remove_squeezable_dimensions\u001b[1;34m(labels, predictions, weights, expected_rank_diff)\u001b[0m\n\u001b[0;32m    671\u001b[0m   \"\"\"\n\u001b[0;32m    672\u001b[0m   labels, predictions = confusion_matrix.remove_squeezable_dimensions(\n\u001b[1;32m--> 673\u001b[1;33m       labels, predictions, expected_rank_diff=expected_rank_diff)\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\ops\\confusion_matrix.py\u001b[0m in \u001b[0;36mremove_squeezable_dimensions\u001b[1;34m(labels, predictions, expected_rank_diff, name)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mrank_diff\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected_rank_diff\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36msqueeze\u001b[1;34m(input, axis, name, squeeze_dims)\u001b[0m\n\u001b[0;32m   2318\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2319\u001b[0m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2320\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_squeeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m_squeeze\u001b[1;34m(input, squeeze_dims, name)\u001b[0m\n\u001b[0;32m   3556\u001b[0m   \"\"\"\n\u001b[0;32m   3557\u001b[0m   result = _op_def_lib.apply_op(\"Squeeze\", input=input,\n\u001b[1;32m-> 3558\u001b[1;33m                                 squeeze_dims=squeeze_dims, name=name)\n\u001b[0m\u001b[0;32m   3559\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2631\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2632\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python 3.5\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can not squeeze dim[0], expected a dimension of 1, got 6 for 'sparse_softmax_cross_entropy_loss/remove_squeezable_dimensions/Squeeze' (op: 'Squeeze') with input shapes: [6]."
     ]
    }
   ],
   "source": [
    "labels = [1, 0, 1, 1, 1, 1]\n",
    "logits = [1, 0, 1, 1, 1, 1]\n",
    "\n",
    "labels = tf.constant(labels)\n",
    "logits = tf.constant(logits)\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 8, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "data = np.random.randn(1, 8, 8, 1)\n",
    "data_tensor = tf.convert_to_tensor(data,\n",
    "                                   dtype=tf.float32)\n",
    "print(data_tensor.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(3,), dtype=string)\n",
      "[b'1', b'1', b'1']\n"
     ]
    }
   ],
   "source": [
    "files_list = [\"1\", \"1\", \"1\"]\n",
    "files_list_tensor = tf.constant(files_list)\n",
    "print(files_list_tensor)\n",
    "files_list_new = tf.Session().run(files_list_tensor)\n",
    "files_list_new = files_list_new.tolist()\n",
    "print(files_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob as glob\n",
    "def get_files_list(file_dir, file_type=\"txt\", start_idx=None, end_idx=None):\n",
    "    \"\"\"\n",
    "    get the files list\n",
    "    :param file_dir: file directory\n",
    "    :param file_type: type of files, \"*\" is to get all files in this folder\n",
    "    :param start_idx: start index\n",
    "    :param end_idx: end index\n",
    "    :return:\n",
    "        file_list: a list containing full file path\n",
    "    \"\"\"\n",
    "    pattern = \"/*.\" + file_type\n",
    "    file_list = sorted(glob(file_dir + pattern))\n",
    "    total_num = len(file_list)\n",
    "    if type(start_idx) is int and start_idx > total_num:\n",
    "        start_idx = None\n",
    "    if type(end_idx) is int and end_idx > total_num:\n",
    "        end_idx = None\n",
    "    file_list = file_list[start_idx:end_idx]\n",
    "\n",
    "    return file_list\n",
    "\n",
    "def read_data(cover_files_path, stego_files_path, start_idx=None, end_idx=None, is_shuffle=True):\n",
    "    \"\"\"\n",
    "    read file names from the storage\n",
    "    :param cover_files_path: the folder name of cover files\n",
    "    :param stego_files_path: the folder name of stego files\n",
    "    :param start_idx: the start index\n",
    "    :param end_idx: the end index\n",
    "    :param is_shuffle: whether shuffle or not (default is True)\n",
    "    :return:\n",
    "        cover_data_list: list of cover data\n",
    "        cover_label_list: list of cover label\n",
    "        stego_data_list: list of stego data\n",
    "        stego_label_list: list of stego label\n",
    "    \"\"\"\n",
    "    cover_files_list = get_files_list(cover_files_path)         # data list of cover files\n",
    "    stego_files_list = get_files_list(stego_files_path)         # data list of stego files\n",
    "    sample_num_cover = len(cover_files_list)                    # total pairs of samples (cover)\n",
    "    sample_num_stego = len(stego_files_list)                    # total pairs of samples (stego)\n",
    "    sample_num = min(sample_num_cover, sample_num_stego)        # deal with the quantity inequality of cover and stego\n",
    "\n",
    "    cover_files_list = cover_files_list[:sample_num]            # data list of cover files\n",
    "    stego_files_list = stego_files_list[:sample_num]            # data list of stego files\n",
    "    cover_label_list = np.zeros(sample_num, np.int32)           # label list of cover files\n",
    "    stego_label_list = np.ones(sample_num, np.int32)            # label list of stego files\n",
    "    \n",
    "    data_list = np.hstack((cover_files_list, stego_files_list))\n",
    "    label_list = np.hstack((cover_label_list, stego_label_list))\n",
    "    \n",
    "    temp = np.array([data_list, label_list])\n",
    "    temp_t = temp.transpose()\n",
    "\n",
    "    if is_shuffle is True:\n",
    "        np.random.shuffle(temp_t)\n",
    "\n",
    "    if start_idx is not None and start_idx > sample_num:\n",
    "        start_idx = 0\n",
    "    if end_idx is not None and end_idx > sample_num:\n",
    "        end_idx = sample_num\n",
    "\n",
    "    data_list = list(temp_t[start_idx:end_idx, 0])\n",
    "    label_list = list(temp_t[start_idx:end_idx, 1])\n",
    "\n",
    "    return data_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "cover_files_path = r\"E:\\Myself\\2.database\\data_1000\\txt\\cover\\128\"\n",
    "stego_files_path = r\"E:\\Myself\\2.database\\data_1000\\txt\\cover\\128\"\n",
    "data_list, label_list = read_data(cover_files_path, stego_files_path)\n",
    "print(np.shape(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_read_batch(text_files_list, height=200, width=576, channel=1, separator=\",\"):\n",
    "    \"\"\"\n",
    "    read all txt files into the memory\n",
    "\n",
    "    :param text_files_list: text files list\n",
    "    :param height: the height of QMDCT matrix\n",
    "    :param width: the width of QMDCT matrix\n",
    "    :param channel: the channel of QMDCT matrix\n",
    "    :param separator: separator of each elements in text file\n",
    "\n",
    "    :return:\n",
    "        data: QMDCT matrixs, ndarry, shape: [files_num, height, width, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    files_num = len(text_files_list)\n",
    "    data = np.zeros([files_num, height, width, 1], dtype=np.float32)\n",
    "\n",
    "    i = 0\n",
    "    for text_file_path in text_files_list:\n",
    "        content = text_read(text_file_path, height=height, width=width, channel=channel, separator=separator)\n",
    "        data[i] = content\n",
    "        i = i + 1\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'> (2,)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'> (2,)\n"
     ]
    }
   ],
   "source": [
    "image = tf.cast(data_list[:2], tf.string)\n",
    "label = tf.cast(label_list[:2], tf.int32)\n",
    "\n",
    "print(type(image), image.get_shape())\n",
    "print(type(label), label.get_shape())\n",
    "\n",
    "# # make an input queue\n",
    "input_queue = tf.train.slice_input_producer([image, label])\n",
    "\n",
    "files_list_tensor = input_queue[0]\n",
    "label = input_queue[1]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"\", files_list_tensor.eval())\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     a = sess.run([files_list_tensor])\n",
    "# text_file_path = text_file_path.tolist()\n",
    "# print(text_file_path)\n",
    "\n",
    "# def get_batch(image, label, batch_size, capacity):\n",
    "    \n",
    "#     image = tf.cast(image, tf.string)\n",
    "#     label = tf.cast(label, tf.int32)\n",
    "\n",
    "#     # make an input queue\n",
    "#     input_queue = tf.train.slice_input_producer([image, label])\n",
    "    \n",
    "#     files_list_tensor = input_queue[0]\n",
    "#     label = input_queue[1]\n",
    "    \n",
    "#     text_file_path = tf.Session().run(files_list_tensor)\n",
    "#     text_file_path = text_file_path.tolist()\n",
    "#     print(text_file_path)\n",
    "    \n",
    "#     image = text_read_batch(text_file_path, height=200, width=576, channel=1)\n",
    "    \n",
    "#     image = tf.cast(image, tf.float32)\n",
    "    \n",
    "#     image_batch, label_batch = tf.train.batch([image, label],\n",
    "#                                                 batch_size= batch_size,\n",
    "#                                                 num_threads= 64, \n",
    "#                                                 capacity = capacity)\n",
    "\n",
    "    \n",
    "#     label_batch = tf.reshape(label_batch, [batch_size])\n",
    "#     image_batch = tf.cast(image_batch, tf.float32)\n",
    "    \n",
    "#     return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_batch(data_list, label_list, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8]\n",
      "[7 1 6 3 2 4 5 8 0]\n",
      "['&' 'b' 'c' '2' '1' '*' '3' '#' 'a']\n",
      "['Symbol' 'Letter' 'Letter' 'Number' 'Number' 'Symbol' 'Number' 'Symbol'\n",
      " 'Letter']\n",
      "-----------------\n",
      "['&' 'b' 'c' '2']\n",
      "['Symbol' 'Letter' 'Letter' 'Number']\n",
      "['1' '*' '3' '#']\n",
      "['Number' 'Symbol' 'Number' 'Symbol']\n",
      "['a' 'a' '#' 'c']\n",
      "['Letter' 'Letter' 'Symbol' 'Letter']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    " \n",
    "class DataSet(object):\n",
    " \n",
    "    def __init__(self, images, labels, num_examples):\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0  # 完成遍历轮数\n",
    "        self._index_in_epochs = 0   # 调用next_batch()函数后记住上一次位置\n",
    "        self._num_examples = num_examples  # 训练样本数\n",
    " \n",
    "    def next_batch(self, batch_size, fake_data=False, shuffle=True):\n",
    "        start = self._index_in_epochs\n",
    " \n",
    "        if self._epochs_completed == 0 and start == 0 and shuffle:\n",
    "            index0 = np.arange(self._num_examples)\n",
    "            print(index0)\n",
    "            np.random.shuffle(index0)\n",
    "            print(index0)\n",
    "            self._images = np.array(self._images)[index0]\n",
    "            self._labels = np.array(self._labels)[index0]\n",
    "            print(self._images)\n",
    "            print(self._labels)\n",
    "            print(\"-----------------\")\n",
    " \n",
    "        if start + batch_size > self._num_examples:\n",
    "            self._epochs_completed += 1\n",
    "            rest_num_examples = self._num_examples - start\n",
    "            images_rest_part = self._images[start:self._num_examples]\n",
    "            labels_rest_part = self._labels[start:self._num_examples]\n",
    "            if shuffle:\n",
    "                index = np.arange(self._num_examples)\n",
    "                np.random.shuffle(index)\n",
    "                self._images = self._images[index]\n",
    "                self._labels = self._labels[index]\n",
    "            start = 0\n",
    "            self._index_in_epochs = batch_size - rest_num_examples\n",
    "            end = self._index_in_epochs\n",
    "            images_new_part = self._images[start:end]\n",
    "            labels_new_part = self._labels[start:end]\n",
    "            return np.concatenate((images_rest_part, images_new_part), axis=0), np.concatenate(\n",
    "                (labels_rest_part, labels_new_part), axis=0)\n",
    " \n",
    "        else:\n",
    "            self._index_in_epochs += batch_size\n",
    "            end = self._index_in_epochs\n",
    "            return self._images[start:end], self._labels[start:end]\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    input = np.array(['a', 'b', '1', '2', '*', '3', 'c', '&', '#'])\n",
    "    output = np.array([\"Letter\", \"Letter\", \"Number\", \"Number\", \"Symbol\", \"Number\", \"Letter\", \"Symbol\", \"Symbol\"])\n",
    "    ds = DataSet(input, output, 9)\n",
    "    for i in range(3):\n",
    "        image_batch, label_batch = ds.next_batch(4)\n",
    "        print(image_batch)\n",
    "        print(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(128, 128, 128, 1)\n",
    "data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_1:0\", shape=(128, 128, 128), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.argmax(input=data_tensor, axis=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sum = tf.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: block_sampling, shape: (4, 4, 4)\n",
      "data: \n",
      "[-0.17161893  0.74965953 -1.02802025 -0.13199344  0.3971187   0.77830126\n",
      "  0.6487124   0.59065164]\n",
      "[ 0.66747562  0.63769836 -0.14392037  0.80668337  0.57702981  1.58056001\n",
      "  1.13983076 -0.30065581]\n",
      "[-1.31718233  0.53297881 -0.98698308  1.41755867  0.77626787 -1.59162214\n",
      " -0.32667824  0.47986914]\n",
      "[ 0.08339791 -0.06889767  0.53059466  0.05671615  1.89683478  0.12357386\n",
      "  1.04915767  1.10868765]\n",
      "[ 0.09465779  0.32616215  1.55016374 -0.15060254 -0.17464154 -0.51680534\n",
      "  0.64633626 -1.02279008]\n",
      "[ 0.14910313  1.04369867  0.54898172  0.12493159 -1.77038259  0.48065937\n",
      " -0.1349778   1.53357493]\n",
      "[-0.04294125  1.21117203  0.874446   -0.00136423  1.11037878 -0.67250144\n",
      "  0.45949044  0.97927662]\n",
      "[ 1.3988393  -1.539521    0.76896467  0.97068279  0.2023362  -0.21423867\n",
      "  0.18706427  1.71685977]\n",
      "0:  [[-0.17161892 -1.02802026  0.39711869  0.6487124 ]\n",
      " [-1.3171823  -0.98698306  0.77626789 -0.32667825]\n",
      " [ 0.09465779  1.55016375 -0.17464153  0.64633626]\n",
      " [-0.04294125  0.87444603  1.11037874  0.45949045]]\n",
      "1:  [[  7.49659538e-01  -1.31993443e-01   7.78301239e-01   5.90651631e-01]\n",
      " [  5.32978833e-01   1.41755867e+00  -1.59162211e+00   4.79869157e-01]\n",
      " [  3.26162159e-01  -1.50602534e-01  -5.16805351e-01  -1.02279007e+00]\n",
      " [  1.21117198e+00  -1.36423227e-03  -6.72501445e-01   9.79276597e-01]]\n",
      "2:  [[ 0.66747564 -0.14392038  0.57702982  1.13983071]\n",
      " [ 0.08339791  0.53059465  1.89683473  1.04915762]\n",
      " [ 0.14910312  0.54898173 -1.77038264 -0.1349778 ]\n",
      " [ 1.39883935  0.76896465  0.20233621  0.18706428]]\n",
      "3:  [[ 0.63769835  0.80668336  1.58055997 -0.30065581]\n",
      " [-0.06889767  0.05671615  0.12357386  1.10868764]\n",
      " [ 1.04369867  0.12493159  0.48065937  1.53357494]\n",
      " [-1.53952098  0.9706828  -0.21423867  1.71685982]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "output = block_sampling_layer(data_tensor, 2)\n",
    "with tf.Session() as sess:\n",
    "    output_np = output.eval()\n",
    "#     print(sess.run(data_tensor))\n",
    "#     print(sess.run(output))\n",
    "#     print(\"output_np\", output_np)\n",
    "#     print(np.shape(output_np))\n",
    "    print(\"data: \")\n",
    "    print(data[0,0,:,0])\n",
    "    print(data[0,1,:,0])\n",
    "    print(data[0,2,:,0])\n",
    "    print(data[0,3,:,0])\n",
    "    print(data[0,4,:,0])\n",
    "    print(data[0,5,:,0])\n",
    "    print(data[0,6,:,0])\n",
    "    print(data[0,7,:,0])\n",
    "    \n",
    "    print(\"0: \", output_np[0,:,:,0])\n",
    "    print(\"1: \", output_np[0,:,:,1])\n",
    "    print(\"2: \", output_np[0,:,:,2])\n",
    "    print(\"3: \", output_np[0,:,:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.str_'>\n",
      "['0', '0', '0', '1', '1']\n",
      "['0', '1', '0', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "y_train_batch1 = y_train_batch[:int(10 / 2)]\n",
    "y_train_batch2 = y_train_batch[int(10 / 2):]\n",
    "new_labels = list(np.array(np.array(np.array(y_train_batch1) == np.array(y_train_batch2), dtype=np.int32), dtype=np.str))\n",
    "print(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "labels = tf.placeholder(dtype=tf.int32, shape=(None, ), name=\"label\")\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(labels, feed_dict={labels: new_labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments_extraction(input_data):\n",
    "    \"\"\"\n",
    "    this function is used for dimension unification in Jessica's paper for steganalysis of arbitrary size\n",
    "    calculate the moments of feature maps -- mean, variance, maximum and minimum\n",
    "    :param input_data: the input data tensor [batch_size, height, width, channels]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    data_max = tf.reduce_max(input_data, axis=[1, 2], keep_dims=True, name=\"moments_max\")\n",
    "    data_min = tf.reduce_min(input_data, axis=[1, 2], keep_dims=True, name=\"moments_min\")\n",
    "    data_mean, data_variance = tf.nn.moments(input_data, axes=[1, 2], keep_dims=True, name=\"moments_mean_var\")\n",
    "    \n",
    "    input_data_sub_mean = tf.subtract(input_data, data_mean)\n",
    "    data_variance_inverse = tf.divide(1.0, data_variance)\n",
    "    data_kurtosis = tf.multiply(tf.reduce_mean(tf.pow(input_data_sub_mean, 4)), tf.pow(data_variance_inverse, 4))\n",
    "    data_skwness = tf.multiply(tf.reduce_mean(tf.pow(input_data_sub_mean, 3)), tf.pow(data_variance_inverse, 3))\n",
    "    \n",
    "    moments = tf.concat([data_max, data_min, data_mean, data_variance, data_kurtosis, data_skwness], axis=1, name=\"moments\")\n",
    "\n",
    "    return moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 1, 2)\n",
      "[[  1.   3.   5.   7.   9.]\n",
      " [ 11.  13.  15.  17.  19.]]\n",
      "[[ 0.03030303]]\n",
      "0-0:\n",
      " [[  1.   3.   5.   7.   9.]\n",
      " [ 11.  13.  15.  17.  19.]]\n",
      "0-1:\n",
      " [[  2.   4.   6.   8.  10.]\n",
      " [ 12.  14.  16.  18.  20.]]\n",
      "1-0:\n",
      " [[ -1.  -3.  -5.  -7.  -9.]\n",
      " [-11. -13. -15. -17. -19.]]\n",
      "1-1:\n",
      " [[ -2.  -4.  -6.  -8. -10.]\n",
      " [-12. -14. -16. -18. -20.]]\n",
      "[[[  1.90000000e+01   2.00000000e+01]]\n",
      "\n",
      " [[  1.00000000e+00   2.00000000e+00]]\n",
      "\n",
      " [[  1.00000000e+01   1.10000000e+01]]\n",
      "\n",
      " [[  3.30000000e+01   3.30000000e+01]]\n",
      "\n",
      " [[  1.63063162e-03   1.63063162e-03]]\n",
      "\n",
      " [[  0.00000000e+00   0.00000000e+00]]]\n",
      "[[  1.90000000e+01]\n",
      " [  1.00000000e+00]\n",
      " [  1.00000000e+01]\n",
      " [  3.30000000e+01]\n",
      " [  1.63063162e-03]\n",
      " [  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "data_tensor = tf.constant(value=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17, 18,19,20,\n",
    "                                 -1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12,-13,-14,-15,-16,-17, -18,-19,-20],\n",
    "                          shape=[2,2,5,2],\n",
    "                          dtype=tf.float32)\n",
    "\n",
    "moments = moments_extraction(data_tensor)\n",
    "print(moments.get_shape())\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    moments_out = sess.run(moments)\n",
    "    data_out = sess.run(data_tensor)\n",
    "    data_variance_inverse_out = sess.run(data_variance_inverse)\n",
    "    print(data_out[0][:,:,0])\n",
    "    print(data_variance_inverse_out[0][:,:,0])\n",
    "#     print(data_kurtosis_out[0][:,:,0])\n",
    "#     print(data_skwness_out[0][:,:,0])\n",
    "    print(\"0-0:\\n\", data_out[0][:,:,0])\n",
    "    print(\"0-1:\\n\", data_out[0][:,:,1])\n",
    "    \n",
    "    print(\"1-0:\\n\", data_out[1][:,:,0])\n",
    "    print(\"1-1:\\n\", data_out[1][:,:,1])\n",
    "    \n",
    "    print(moments_out[0])\n",
    "    print(moments_out[0][:,:,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14  1  1  0  8]\n"
     ]
    }
   ],
   "source": [
    "nbins = 5\n",
    "value_range = [0.0, 5.0]\n",
    "# new_values = tf.constant(value=[-1.0, 0.0, 1.5, 2.0, 5.0, 15, -1.0, 0.0, 1.5, 2.0, 5.0, 15, \n",
    "#                                -1.0, 0.0, 1.5, 2.0, 5.0, 15, -1.0, 0.0, 1.5, 2.0, 5.0, 15],\n",
    "#                          dtype=tf.float32,\n",
    "#                         shape=[2, 2, 6, 1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    hist = tf.histogram_fixed_width(moments, value_range, nbins=5)\n",
    "    hist_out = sess.run(hist)\n",
    "    print(hist_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_statistics(audio_data, sampling_rate=44100, n_mfcc=40):\n",
    "    \"\"\"\n",
    "    calculate the statistics of mfcc coefficients\n",
    "    :param audio_data: audio data, ndarray [length, channel]\n",
    "    :param sampling_rate: sampling rate of audio data, default: 44100\n",
    "    :param n_mfcc: number of mfcc, default: 40\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    mfcc_feature = []\n",
    "    for i in range(2):\n",
    "        audio_data_mono = audio_data[0][i]\n",
    "        mfcc_coefficients = librosa.feature.mfcc(y=audio_data_mono, sr=sampling_rate, n_mfcc=n_mfcc)\n",
    "\n",
    "        mfcc_max = np.max(mfcc_coefficients.T, axis=0)\n",
    "        mfcc_feature.append(mfcc_max)\n",
    "\n",
    "        mfcc_min = np.min(mfcc_coefficients.T, axis=0)\n",
    "        mfcc_feature.append(mfcc_min)\n",
    "\n",
    "        mfcc_mean = np.mean(mfcc_coefficients.T, axis=0)\n",
    "        mfcc_feature.append(mfcc_mean)\n",
    "\n",
    "        mfcc_var = np.var(mfcc_coefficients.T, axis=0)\n",
    "        mfcc_feature.append(mfcc_var)\n",
    "\n",
    "        mfcc_var_inverse = np.divide(1.0, mfcc_var)\n",
    "        mfcc_kurtosis = np.multiply(np.power(mfcc_mean, 4), np.power(mfcc_var_inverse, 4))\n",
    "        mfcc_feature.append(mfcc_kurtosis)\n",
    "\n",
    "        mfcc_skewness = np.multiply(np.power(mfcc_mean, 3), np.power(mfcc_var_inverse, 3))\n",
    "        mfcc_feature.append(mfcc_skewness)\n",
    "\n",
    "    mfcc_feature = np.array(mfcc_feature)\n",
    "\n",
    "    return mfcc_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "audio1_file_path = \"E:/Myself/2.database/3.cover/cover_10s/128/wav10s_00001.mp3\"\n",
    "audio2_file_path = \"E:/Myself/2.database/4.stego/EECS/EECS_B_128_W_2_H_7_ER_10/wav10s_00001.mp3\"\n",
    "audio1_data = librosa.load(audio1_file_path, sr=44100, mono=True, duration=1)\n",
    "audio2_data = librosa.load(audio2_file_path, sr=44100, mono=False, duration=1)\n",
    "\n",
    "print(np.shape(audio1_data))\n",
    "print(np.shape(audio2_data))\n",
    "      \n",
    "# for i in range(2):\n",
    "#     audio_data_mono = audio1_data[0][i]\n",
    "#     print(np.shape(audio_data_mono))\n",
    "#     mfcc_coefficients = librosa.feature.mfcc(y=audio_data_mono, sr=44100, n_mfcc=40)\n",
    "#     print(np.shape(mfcc_coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44100,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(audio2_data[0][0]))\n",
    "print(np.shape(audio2_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 40)\n"
     ]
    }
   ],
   "source": [
    "# audio1_left_mfcc_feature = get_mfcc_statistics(audio1_data[0][0])\n",
    "# audio2_left_mfcc_feature = get_mfcc_statistics(audio2_data[0][0])\n",
    "# audio1_left_mfcc_feature, audio2_left_mfcc_feature\n",
    "\n",
    "# audio1_right_mfcc_feature = get_mfcc_statistics(audio1_data[0][1])\n",
    "# audio2_right_mfcc_feature = get_mfcc_statistics(audio2_data[0][1])\n",
    "# audio1_right_mfcc_feature, audio2_right_mfcc_feature\n",
    "\n",
    "audio1_left_mfcc_feature = get_mfcc_statistics(audio1_data)\n",
    "audio2_left_mfcc_feature = get_mfcc_statistics(audio2_data)\n",
    "audio1_left_mfcc_feature, audio2_left_mfcc_feature\n",
    "print(np.shape(audio1_left_mfcc_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -6.96375619e-01,   3.44991943e-02,   2.30569313e+00,\n",
       "          1.06476374e+00,  -8.04822502e+00,  -9.70736420e-01,\n",
       "          7.98313566e+00,  -2.54826506e+00,   1.70339142e+01,\n",
       "         -2.35001315e+00,  -9.91006360e+00,  -6.82365746e+00,\n",
       "         -2.09166778e+01,  -1.44149134e+02,   4.89978905e+00,\n",
       "          7.61643376e+00,   3.89099694e+00,   7.86649444e+00,\n",
       "          1.53171715e+00,  -3.42669292e+01,  -4.13740114e+00,\n",
       "          6.82122168e+00,   3.40740539e+00,  -2.30641266e+00,\n",
       "         -7.00318653e+00,   3.51419688e+00,  -2.47708259e+00,\n",
       "         -8.73119001e+00,  -5.46994037e+00,   2.57454906e+00,\n",
       "         -1.75205876e+01,  -3.85847380e+00,  -4.12441352e+00,\n",
       "         -1.66945265e+00,  -3.45783285e+01,   1.28941841e+01,\n",
       "          5.30289870e+01,   3.63281393e+00,   1.35370550e+01,\n",
       "         -2.89616900e+01],\n",
       "       [  9.34082650e-03,  -7.71183398e-01,  -6.92618040e-01,\n",
       "          1.87300685e+00,  -2.69620392e+00,  -2.53248990e+00,\n",
       "         -3.10697894e-01,  -9.22248274e+01,  -4.73736909e-01,\n",
       "         -7.56370306e+01,  -3.87480194e+00,  -3.77842694e+00,\n",
       "         -1.19682824e+00,  -5.52069484e+00,   3.02522061e+00,\n",
       "         -3.52586925e-01,  -3.64173332e-01,  -2.00085397e+00,\n",
       "         -1.60813471e+00,  -1.21895911e-01,   5.47736553e+00,\n",
       "          1.15751356e+00,  -2.57293935e+00,   1.00748307e+00,\n",
       "         -7.93899185e+00,  -4.71883609e+00,   4.89058962e-01,\n",
       "          1.63999945e+00,  -2.04791193e+00,  -7.88955405e-01,\n",
       "          2.78652616e+00,   9.68955361e-01,  -4.20206631e+00,\n",
       "          7.09794974e-01,  -5.08189573e+00,  -4.21785479e+00,\n",
       "          5.96315747e+00,  -3.05547880e+00,   7.38248704e-01,\n",
       "          3.28959826e+00],\n",
       "       [  9.28782752e-02,  -1.78752625e-01,  -6.35418748e-01,\n",
       "          3.79982207e-02,   1.67594915e+00,  -5.43998202e-01,\n",
       "         -9.63144544e-02,  -8.28720169e-01,   2.36941178e+00,\n",
       "         -2.87216441e+00,   2.32124552e+00,  -1.35445211e+01,\n",
       "          2.54542873e+00,   1.70395025e+00,   1.20193464e+00,\n",
       "         -1.02808827e+00,   2.50946081e+01,  -1.30602046e+00,\n",
       "          1.00643073e+00,   1.05759011e+00,   8.75604673e+00,\n",
       "          1.40755044e+00,  -1.00320215e+01,   9.49422395e-01,\n",
       "          1.55297790e+01,   3.93943231e+00,   3.33087390e+00,\n",
       "          7.01544947e+00,  -1.66379827e+00,   6.12111081e-01,\n",
       "          5.71807019e-01,   1.49946695e+01,  -5.83765956e+00,\n",
       "         -1.16483077e+00,   4.95569154e-01,  -1.10173574e+00,\n",
       "         -7.87373050e-01,  -3.17086535e+01,   6.96861773e+00,\n",
       "          6.61867729e+00],\n",
       "       [  3.89401214e-01,   1.91783095e-01,   3.49282755e+00,\n",
       "         -1.02090111e+00,  -2.66686891e+00,   2.50005782e+00,\n",
       "         -1.19121759e+00,  -1.97733411e+00,   4.93012313e+00,\n",
       "          1.68341251e+00,   8.76554176e-01,   2.10916705e+00,\n",
       "         -7.32982677e+00,  -4.21838986e+00,   9.47450940e-01,\n",
       "          8.07679095e+00,   5.94703643e+00,   2.24738755e-01,\n",
       "          3.39480034e+00,   9.41668797e-01,  -4.74604161e+00,\n",
       "          4.01769978e+00,   3.50926820e+00,  -4.95074010e+00,\n",
       "         -5.37394872e-01,  -6.51919943e+00,  -8.14513508e+00,\n",
       "          2.33881595e+00,   4.61821149e-01,  -7.35183488e-01,\n",
       "         -2.80554125e+00,  -4.92121801e+00,  -2.58030491e+00,\n",
       "         -1.36621163e+00,  -6.12333178e+00,   7.32727499e-01,\n",
       "         -3.87091305e-01,   3.09334119e+00,   3.80652020e+00,\n",
       "         -4.72898991e+00],\n",
       "       [ -1.19605591e+00,  -1.49328082e+00,  -1.82401757e+01,\n",
       "          4.12732933e+00,   1.58764132e+01,  -1.30855651e+01,\n",
       "          4.25831605e+00,   4.42982068e+00,  -1.12171848e+01,\n",
       "         -1.98627743e+01,   5.70364863e+00,  -8.10075273e+01,\n",
       "          3.20284541e+01,   2.08653249e+01,   1.02371785e+00,\n",
       "         -4.59042126e+01,   5.97688558e+01,  -6.27950619e+00,\n",
       "         -1.02620146e+01,   4.67272114e-01,   4.24207645e+01,\n",
       "         -1.13294371e+01,  -6.90962463e+01,   2.06611269e+01,\n",
       "          5.01684942e+01,   3.38592644e+01,   3.61555397e+01,\n",
       "          1.78220614e+01,  -8.81945914e+00,   5.24347263e+00,\n",
       "          1.25072453e+01,   5.69144793e+01,  -1.33195830e+01,\n",
       "          7.92301641e-01,   2.27094898e+01,  -7.59945955e+00,\n",
       "         -1.60451797e+00,  -2.41226506e+02,   1.25146461e+01,\n",
       "          3.67919452e+01],\n",
       "       [ -8.95707428e-01,  -1.11788299e+00,  -1.33897505e+01,\n",
       "          3.11174836e+00,   1.21608072e+01,  -9.66180231e+00,\n",
       "          3.21104602e+00,   3.34111064e+00,  -8.30011641e+00,\n",
       "         -1.45547875e+01,   4.30898381e+00,  -5.60531275e+01,\n",
       "          2.51407692e+01,   1.60974582e+01,   7.68775099e-01,\n",
       "         -3.27549958e+01,   4.94848336e+01,  -4.67359637e+00,\n",
       "         -7.60177673e+00,   3.50659182e-01,   3.39003103e+01,\n",
       "         -8.38208714e+00,  -4.82861109e+01,   1.59351348e+01,\n",
       "          4.06899886e+01,   2.66581661e+01,   2.85762883e+01,\n",
       "          1.36889436e+01,  -6.54422685e+00,   3.95896044e+00,\n",
       "          9.53531652e+00,   4.68199784e+01,  -9.83195794e+00,\n",
       "          5.94816690e-01,   1.75682290e+01,  -5.64709690e+00,\n",
       "         -1.20099090e+00,  -1.51062628e+02,   9.54105579e+00,\n",
       "          2.91109234e+01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(audio1_left_mfcc_feature - audio2_left_mfcc_feature) / audio1_left_mfcc_feature * 100\n",
    "(audio1_right_mfcc_feature - audio2_right_mfcc_feature) / audio1_right_mfcc_feature * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BN11/BN11/moving_mean/biased': [2],\n",
       " 'BN11/BN11/moving_mean/local_step': [],\n",
       " 'BN11/beta': [2],\n",
       " 'BN11/beta/Adam': [2],\n",
       " 'BN11/beta/Adam_1': [2],\n",
       " 'BN11/gamma': [2],\n",
       " 'BN11/gamma/Adam': [2],\n",
       " 'BN11/gamma/Adam_1': [2],\n",
       " 'BN11/moving_mean': [2],\n",
       " 'BN11/moving_variance': [2],\n",
       " 'BN1_3/BN1_3/moving_mean/biased': [32],\n",
       " 'BN1_3/BN1_3/moving_mean/local_step': [],\n",
       " 'BN1_3/beta': [32],\n",
       " 'BN1_3/beta/Adam': [32],\n",
       " 'BN1_3/beta/Adam_1': [32],\n",
       " 'BN1_3/gamma': [32],\n",
       " 'BN1_3/gamma/Adam': [32],\n",
       " 'BN1_3/gamma/Adam_1': [32],\n",
       " 'BN1_3/moving_mean': [32],\n",
       " 'BN1_3/moving_variance': [32],\n",
       " 'BN2_3/BN2_3/moving_mean/biased': [64],\n",
       " 'BN2_3/BN2_3/moving_mean/local_step': [],\n",
       " 'BN2_3/beta': [64],\n",
       " 'BN2_3/beta/Adam': [64],\n",
       " 'BN2_3/beta/Adam_1': [64],\n",
       " 'BN2_3/gamma': [64],\n",
       " 'BN2_3/gamma/Adam': [64],\n",
       " 'BN2_3/gamma/Adam_1': [64],\n",
       " 'BN2_3/moving_mean': [64],\n",
       " 'BN2_3/moving_variance': [64],\n",
       " 'BN3_3/BN3_3/moving_mean/biased': [128],\n",
       " 'BN3_3/BN3_3/moving_mean/local_step': [],\n",
       " 'BN3_3/beta': [128],\n",
       " 'BN3_3/beta/Adam': [128],\n",
       " 'BN3_3/beta/Adam_1': [128],\n",
       " 'BN3_3/gamma': [128],\n",
       " 'BN3_3/gamma/Adam': [128],\n",
       " 'BN3_3/gamma/Adam_1': [128],\n",
       " 'BN3_3/moving_mean': [128],\n",
       " 'BN3_3/moving_variance': [128],\n",
       " 'BN4_3/BN4_3/moving_mean/biased': [256],\n",
       " 'BN4_3/BN4_3/moving_mean/local_step': [],\n",
       " 'BN4_3/beta': [256],\n",
       " 'BN4_3/beta/Adam': [256],\n",
       " 'BN4_3/beta/Adam_1': [256],\n",
       " 'BN4_3/gamma': [256],\n",
       " 'BN4_3/gamma/Adam': [256],\n",
       " 'BN4_3/gamma/Adam_1': [256],\n",
       " 'BN4_3/moving_mean': [256],\n",
       " 'BN4_3/moving_variance': [256],\n",
       " 'BN5_3/BN5_3/moving_mean/biased': [512],\n",
       " 'BN5_3/BN5_3/moving_mean/local_step': [],\n",
       " 'BN5_3/beta': [512],\n",
       " 'BN5_3/beta/Adam': [512],\n",
       " 'BN5_3/beta/Adam_1': [512],\n",
       " 'BN5_3/gamma': [512],\n",
       " 'BN5_3/gamma/Adam': [512],\n",
       " 'BN5_3/gamma/Adam_1': [512],\n",
       " 'BN5_3/moving_mean': [512],\n",
       " 'BN5_3/moving_variance': [512],\n",
       " 'BN7/BN7/moving_mean/biased': [4096],\n",
       " 'BN7/BN7/moving_mean/local_step': [],\n",
       " 'BN7/beta': [4096],\n",
       " 'BN7/beta/Adam': [4096],\n",
       " 'BN7/beta/Adam_1': [4096],\n",
       " 'BN7/gamma': [4096],\n",
       " 'BN7/gamma/Adam': [4096],\n",
       " 'BN7/gamma/Adam_1': [4096],\n",
       " 'BN7/moving_mean': [4096],\n",
       " 'BN7/moving_variance': [4096],\n",
       " 'BN9/BN9/moving_mean/biased': [512],\n",
       " 'BN9/BN9/moving_mean/local_step': [],\n",
       " 'BN9/beta': [512],\n",
       " 'BN9/beta/Adam': [512],\n",
       " 'BN9/beta/Adam_1': [512],\n",
       " 'BN9/gamma': [512],\n",
       " 'BN9/gamma/Adam': [512],\n",
       " 'BN9/gamma/Adam_1': [512],\n",
       " 'BN9/moving_mean': [512],\n",
       " 'BN9/moving_variance': [512],\n",
       " 'conv10/biases': [2],\n",
       " 'conv10/biases/Adam': [2],\n",
       " 'conv10/biases/Adam_1': [2],\n",
       " 'conv10/weights': [1, 1, 512, 2],\n",
       " 'conv10/weights/Adam': [1, 1, 512, 2],\n",
       " 'conv10/weights/Adam_1': [1, 1, 512, 2],\n",
       " 'conv1_1/biases': [16],\n",
       " 'conv1_1/biases/Adam': [16],\n",
       " 'conv1_1/biases/Adam_1': [16],\n",
       " 'conv1_1/weights': [3, 3, 9, 16],\n",
       " 'conv1_1/weights/Adam': [3, 3, 9, 16],\n",
       " 'conv1_1/weights/Adam_1': [3, 3, 9, 16],\n",
       " 'conv1_2/biases': [32],\n",
       " 'conv1_2/biases/Adam': [32],\n",
       " 'conv1_2/biases/Adam_1': [32],\n",
       " 'conv1_2/weights': [3, 3, 16, 32],\n",
       " 'conv1_2/weights/Adam': [3, 3, 16, 32],\n",
       " 'conv1_2/weights/Adam_1': [3, 3, 16, 32],\n",
       " 'conv2_1/biases': [32],\n",
       " 'conv2_1/biases/Adam': [32],\n",
       " 'conv2_1/biases/Adam_1': [32],\n",
       " 'conv2_1/weights': [3, 3, 32, 32],\n",
       " 'conv2_1/weights/Adam': [3, 3, 32, 32],\n",
       " 'conv2_1/weights/Adam_1': [3, 3, 32, 32],\n",
       " 'conv2_2/biases': [64],\n",
       " 'conv2_2/biases/Adam': [64],\n",
       " 'conv2_2/biases/Adam_1': [64],\n",
       " 'conv2_2/weights': [3, 3, 32, 64],\n",
       " 'conv2_2/weights/Adam': [3, 3, 32, 64],\n",
       " 'conv2_2/weights/Adam_1': [3, 3, 32, 64],\n",
       " 'conv3_1/biases': [64],\n",
       " 'conv3_1/biases/Adam': [64],\n",
       " 'conv3_1/biases/Adam_1': [64],\n",
       " 'conv3_1/weights': [3, 3, 64, 64],\n",
       " 'conv3_1/weights/Adam': [3, 3, 64, 64],\n",
       " 'conv3_1/weights/Adam_1': [3, 3, 64, 64],\n",
       " 'conv3_2/biases': [128],\n",
       " 'conv3_2/biases/Adam': [128],\n",
       " 'conv3_2/biases/Adam_1': [128],\n",
       " 'conv3_2/weights': [3, 3, 64, 128],\n",
       " 'conv3_2/weights/Adam': [3, 3, 64, 128],\n",
       " 'conv3_2/weights/Adam_1': [3, 3, 64, 128],\n",
       " 'conv4_1/biases': [128],\n",
       " 'conv4_1/biases/Adam': [128],\n",
       " 'conv4_1/biases/Adam_1': [128],\n",
       " 'conv4_1/weights': [3, 3, 128, 128],\n",
       " 'conv4_1/weights/Adam': [3, 3, 128, 128],\n",
       " 'conv4_1/weights/Adam_1': [3, 3, 128, 128],\n",
       " 'conv4_2/biases': [256],\n",
       " 'conv4_2/biases/Adam': [256],\n",
       " 'conv4_2/biases/Adam_1': [256],\n",
       " 'conv4_2/weights': [1, 1, 128, 256],\n",
       " 'conv4_2/weights/Adam': [1, 1, 128, 256],\n",
       " 'conv4_2/weights/Adam_1': [1, 1, 128, 256],\n",
       " 'conv5_1/biases': [256],\n",
       " 'conv5_1/biases/Adam': [256],\n",
       " 'conv5_1/biases/Adam_1': [256],\n",
       " 'conv5_1/weights': [3, 3, 256, 256],\n",
       " 'conv5_1/weights/Adam': [3, 3, 256, 256],\n",
       " 'conv5_1/weights/Adam_1': [3, 3, 256, 256],\n",
       " 'conv5_2/biases': [512],\n",
       " 'conv5_2/biases/Adam': [512],\n",
       " 'conv5_2/biases/Adam_1': [512],\n",
       " 'conv5_2/weights': [1, 1, 256, 512],\n",
       " 'conv5_2/weights/Adam': [1, 1, 256, 512],\n",
       " 'conv5_2/weights/Adam_1': [1, 1, 256, 512],\n",
       " 'conv6/biases': [4096],\n",
       " 'conv6/biases/Adam': [4096],\n",
       " 'conv6/biases/Adam_1': [4096],\n",
       " 'conv6/weights': [6, 14, 512, 4096],\n",
       " 'conv6/weights/Adam': [6, 14, 512, 4096],\n",
       " 'conv6/weights/Adam_1': [6, 14, 512, 4096],\n",
       " 'conv8/biases': [512],\n",
       " 'conv8/biases/Adam': [512],\n",
       " 'conv8/biases/Adam_1': [512],\n",
       " 'conv8/weights': [1, 1, 4096, 512],\n",
       " 'conv8/weights/Adam': [1, 1, 4096, 512],\n",
       " 'conv8/weights/Adam_1': [1, 1, 4096, 512],\n",
       " 'global_step': [],\n",
       " 'optimizer/beta1_power': [],\n",
       " 'optimizer/beta2_power': []}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "\n",
    "model_file_path = r\"E:\\Myself\\1.source_code\\tf_audio_steganalysis\\models\\EECS_B_128_W_2_H_7_ER_10-3000\"\n",
    "reader = pywrap_tensorflow.NewCheckpointReader(model_file_path)\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "\n",
    "var_to_shape_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name: optimizer/beta1_power\n",
      "tensor_name: BN2_3/beta\n",
      "tensor_name: conv2_2/biases\n",
      "tensor_name: conv1_2/biases\n",
      "tensor_name: BN5_3/BN5_3/moving_mean/biased\n",
      "tensor_name: BN4_3/gamma\n",
      "tensor_name: BN5_3/BN5_3/moving_mean/local_step\n",
      "tensor_name: BN4_3/beta\n",
      "tensor_name: BN3_3/BN3_3/moving_mean/biased\n",
      "tensor_name: conv1_2/weights\n",
      "tensor_name: conv2_1/biases\n",
      "tensor_name: BN11/gamma\n",
      "tensor_name: BN1_3/gamma\n",
      "tensor_name: conv6/weights\n",
      "tensor_name: BN9/BN9/moving_mean/biased\n",
      "tensor_name: BN5_3/beta\n",
      "tensor_name: optimizer/beta2_power\n",
      "tensor_name: conv6/biases\n",
      "tensor_name: BN11/beta\n",
      "tensor_name: BN11/BN11/moving_mean/local_step\n",
      "tensor_name: BN3_3/moving_variance\n",
      "tensor_name: BN1_3/beta\n",
      "tensor_name: BN7/BN7/moving_mean/local_step\n",
      "tensor_name: BN5_3/moving_variance\n",
      "tensor_name: BN3_3/gamma\n",
      "tensor_name: BN7/gamma\n",
      "tensor_name: conv1_1/biases\n",
      "tensor_name: BN5_3/moving_mean\n",
      "tensor_name: BN2_3/BN2_3/moving_mean/local_step\n",
      "tensor_name: conv5_1/biases\n",
      "tensor_name: conv4_2/weights\n",
      "tensor_name: conv3_2/weights\n",
      "tensor_name: BN3_3/beta\n",
      "tensor_name: BN4_3/BN4_3/moving_mean/biased\n",
      "tensor_name: BN3_3/moving_mean\n",
      "tensor_name: conv4_2/biases\n",
      "tensor_name: BN7/moving_variance\n",
      "tensor_name: BN11/moving_variance\n",
      "tensor_name: conv10/weights\n",
      "tensor_name: BN9/BN9/moving_mean/local_step\n",
      "tensor_name: BN2_3/BN2_3/moving_mean/biased\n",
      "tensor_name: conv3_2/biases\n",
      "tensor_name: BN9/moving_mean\n",
      "tensor_name: conv4_1/weights\n",
      "tensor_name: BN4_3/moving_variance\n",
      "tensor_name: conv4_1/biases\n",
      "tensor_name: conv8/biases\n",
      "tensor_name: BN11/moving_mean\n",
      "tensor_name: BN5_3/gamma\n",
      "tensor_name: BN2_3/gamma\n",
      "tensor_name: conv10/biases\n",
      "tensor_name: BN11/BN11/moving_mean/biased\n",
      "tensor_name: conv5_2/weights\n",
      "tensor_name: conv3_1/biases\n",
      "tensor_name: BN7/beta\n",
      "tensor_name: conv3_1/weights\n",
      "tensor_name: global_step\n",
      "tensor_name: BN1_3/moving_variance\n",
      "tensor_name: BN2_3/moving_mean\n",
      "tensor_name: BN2_3/moving_variance\n",
      "tensor_name: BN4_3/BN4_3/moving_mean/local_step\n",
      "tensor_name: BN7/moving_mean\n",
      "tensor_name: BN9/beta\n",
      "tensor_name: conv8/weights\n",
      "tensor_name: conv2_1/weights\n",
      "tensor_name: conv5_1/weights\n",
      "tensor_name: conv2_2/weights\n",
      "tensor_name: BN9/moving_variance\n",
      "tensor_name: conv1_1/weights\n",
      "tensor_name: BN3_3/BN3_3/moving_mean/local_step\n",
      "tensor_name: conv5_2/biases\n",
      "tensor_name: BN1_3/BN1_3/moving_mean/biased\n",
      "tensor_name: BN7/BN7/moving_mean/biased\n",
      "tensor_name: BN4_3/moving_mean\n",
      "tensor_name: BN1_3/BN1_3/moving_mean/local_step\n",
      "tensor_name: BN1_3/moving_mean\n",
      "tensor_name: BN9/gamma\n"
     ]
    }
   ],
   "source": [
    "for key in var_to_shape_map:\n",
    "    #print (\"tensor_name\",key)\n",
    "    str_name = key\n",
    "    # 因为模型使用Adam算法优化的，在生成的ckpt中，有Adam后缀的tensor\n",
    "    if str_name.find('Adam') > -1:\n",
    "        continue\n",
    "\n",
    "    print('tensor_name:' , str_name)\n",
    "\n",
    "    if str_name.find('/') > -1:\n",
    "        names = str_name.split('/')\n",
    "        # first layer name and weight, bias\n",
    "        layer_name = names[0]\n",
    "        layer_add_info = names[1]\n",
    "    else:\n",
    "        layer_name = str_name\n",
    "        layer_add_info = None\n",
    "\n",
    "#     if layer_add_info == 'weights':\n",
    "#         alexnet[layer_name][0]=reader.get_tensor(key)\n",
    "#     elif layer_add_info == 'biases':\n",
    "#         alexnet[layer_name][1] = reader.get_tensor(key)\n",
    "#     else:\n",
    "#         alexnet[layer_name] = reader.get_tensor(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name conv5_2/weights/Adam_1\n",
      "tensor_name optimizer/beta1_power\n",
      "tensor_name conv10/biases/Adam_1\n",
      "tensor_name BN2_3/beta\n",
      "tensor_name conv2_2/biases\n",
      "tensor_name conv3_1/biases/Adam\n",
      "tensor_name BN2_3/gamma/Adam\n",
      "tensor_name BN11/gamma/Adam_1\n",
      "tensor_name BN2_3/gamma/Adam_1\n",
      "tensor_name conv1_2/biases\n",
      "tensor_name conv1_1/biases/Adam_1\n",
      "tensor_name BN7/beta/Adam_1\n",
      "tensor_name BN5_3/BN5_3/moving_mean/biased\n",
      "tensor_name BN2_3/beta/Adam\n",
      "tensor_name BN5_3/beta/Adam\n",
      "tensor_name conv1_2/biases/Adam\n",
      "tensor_name BN5_3/gamma/Adam\n",
      "tensor_name BN4_3/gamma\n",
      "tensor_name BN3_3/beta/Adam\n",
      "tensor_name BN5_3/BN5_3/moving_mean/local_step\n",
      "tensor_name conv8/biases/Adam_1\n",
      "tensor_name conv1_2/weights/Adam\n",
      "tensor_name BN1_3/gamma/Adam_1\n",
      "tensor_name BN4_3/beta/Adam\n",
      "tensor_name BN5_3/gamma/Adam_1\n",
      "tensor_name conv8/biases/Adam\n",
      "tensor_name conv3_1/weights/Adam\n",
      "tensor_name BN4_3/beta\n",
      "tensor_name conv2_2/biases/Adam\n",
      "tensor_name conv8/weights/Adam\n",
      "tensor_name BN3_3/BN3_3/moving_mean/biased\n",
      "tensor_name BN7/beta/Adam\n",
      "tensor_name conv1_2/weights\n",
      "tensor_name conv2_1/biases\n",
      "tensor_name BN4_3/gamma/Adam\n",
      "tensor_name BN11/gamma\n",
      "tensor_name conv4_2/biases/Adam\n",
      "tensor_name BN5_3/beta/Adam_1\n",
      "tensor_name conv5_2/biases/Adam_1\n",
      "tensor_name BN1_3/gamma\n",
      "tensor_name conv2_1/weights/Adam\n",
      "tensor_name conv4_1/weights/Adam\n",
      "tensor_name BN3_3/gamma/Adam\n",
      "tensor_name conv2_1/biases/Adam\n",
      "tensor_name conv10/weights/Adam\n",
      "tensor_name conv6/weights\n",
      "tensor_name BN7/gamma/Adam_1\n",
      "tensor_name conv5_1/weights/Adam_1\n",
      "tensor_name conv4_2/weights/Adam_1\n",
      "tensor_name BN9/BN9/moving_mean/biased\n",
      "tensor_name BN5_3/beta\n",
      "tensor_name optimizer/beta2_power\n",
      "tensor_name conv6/biases\n",
      "tensor_name BN11/beta\n",
      "tensor_name conv5_2/weights/Adam\n",
      "tensor_name BN11/BN11/moving_mean/local_step\n",
      "tensor_name conv3_1/weights/Adam_1\n",
      "tensor_name conv1_2/weights/Adam_1\n",
      "tensor_name BN3_3/moving_variance\n",
      "tensor_name conv10/biases/Adam\n",
      "tensor_name conv2_2/weights/Adam_1\n",
      "tensor_name BN1_3/beta\n",
      "tensor_name BN7/BN7/moving_mean/local_step\n",
      "tensor_name BN5_3/moving_variance\n",
      "tensor_name BN3_3/gamma\n",
      "tensor_name BN7/gamma\n",
      "tensor_name conv1_1/biases\n",
      "tensor_name BN5_3/moving_mean\n",
      "tensor_name conv4_1/biases/Adam_1\n",
      "tensor_name BN9/beta/Adam\n",
      "tensor_name conv8/weights/Adam_1\n",
      "tensor_name BN3_3/gamma/Adam_1\n",
      "tensor_name BN2_3/BN2_3/moving_mean/local_step\n",
      "tensor_name conv5_1/biases\n",
      "tensor_name BN11/gamma/Adam\n",
      "tensor_name conv4_2/weights\n",
      "tensor_name conv6/weights/Adam\n",
      "tensor_name conv3_2/weights\n",
      "tensor_name BN3_3/beta\n",
      "tensor_name conv2_1/biases/Adam_1\n",
      "tensor_name conv3_2/biases/Adam_1\n",
      "tensor_name BN9/gamma/Adam_1\n",
      "tensor_name BN4_3/BN4_3/moving_mean/biased\n",
      "tensor_name BN3_3/moving_mean\n",
      "tensor_name conv1_1/weights/Adam_1\n",
      "tensor_name conv4_2/biases\n",
      "tensor_name BN7/moving_variance\n",
      "tensor_name BN11/moving_variance\n",
      "tensor_name conv10/weights\n",
      "tensor_name BN9/BN9/moving_mean/local_step\n",
      "tensor_name BN2_3/BN2_3/moving_mean/biased\n",
      "tensor_name conv3_2/biases\n",
      "tensor_name BN3_3/beta/Adam_1\n",
      "tensor_name conv5_1/weights/Adam\n",
      "tensor_name BN9/moving_mean\n",
      "tensor_name BN4_3/gamma/Adam_1\n",
      "tensor_name conv10/weights/Adam_1\n",
      "tensor_name conv4_1/weights\n",
      "tensor_name BN4_3/moving_variance\n",
      "tensor_name conv2_2/weights/Adam\n",
      "tensor_name conv3_2/weights/Adam_1\n",
      "tensor_name conv2_2/biases/Adam_1\n",
      "tensor_name conv4_1/biases\n",
      "tensor_name BN11/beta/Adam\n",
      "tensor_name conv8/biases\n",
      "tensor_name BN11/moving_mean\n",
      "tensor_name conv5_1/biases/Adam\n",
      "tensor_name conv3_2/biases/Adam\n",
      "tensor_name BN9/beta/Adam_1\n",
      "tensor_name BN4_3/beta/Adam_1\n",
      "tensor_name conv1_1/biases/Adam\n",
      "tensor_name conv4_1/weights/Adam_1\n",
      "tensor_name conv4_2/weights/Adam\n",
      "tensor_name BN5_3/gamma\n",
      "tensor_name conv6/weights/Adam_1\n",
      "tensor_name BN2_3/gamma\n",
      "tensor_name conv10/biases\n",
      "tensor_name BN11/beta/Adam_1\n",
      "tensor_name BN11/BN11/moving_mean/biased\n",
      "tensor_name conv5_2/weights\n",
      "tensor_name conv3_1/biases\n",
      "tensor_name conv3_1/biases/Adam_1\n",
      "tensor_name conv5_2/biases/Adam\n",
      "tensor_name BN7/beta\n",
      "tensor_name conv3_1/weights\n",
      "tensor_name conv3_2/weights/Adam\n",
      "tensor_name conv6/biases/Adam_1\n",
      "tensor_name BN2_3/beta/Adam_1\n",
      "tensor_name BN9/gamma/Adam\n",
      "tensor_name BN1_3/beta/Adam_1\n",
      "tensor_name global_step\n",
      "tensor_name BN1_3/moving_variance\n",
      "tensor_name conv4_2/biases/Adam_1\n",
      "tensor_name conv4_1/biases/Adam\n",
      "tensor_name BN2_3/moving_mean\n",
      "tensor_name BN2_3/moving_variance\n",
      "tensor_name BN4_3/BN4_3/moving_mean/local_step\n",
      "tensor_name BN7/moving_mean\n",
      "tensor_name BN9/beta\n",
      "tensor_name conv8/weights\n",
      "tensor_name conv2_1/weights\n",
      "tensor_name conv5_1/weights\n",
      "tensor_name BN1_3/beta/Adam\n",
      "tensor_name conv2_2/weights\n",
      "tensor_name BN9/moving_variance\n",
      "tensor_name BN1_3/gamma/Adam\n",
      "tensor_name conv6/biases/Adam\n",
      "tensor_name conv1_1/weights\n",
      "tensor_name conv5_1/biases/Adam_1\n",
      "tensor_name BN7/gamma/Adam\n",
      "tensor_name BN3_3/BN3_3/moving_mean/local_step\n",
      "tensor_name conv1_2/biases/Adam_1\n",
      "tensor_name conv5_2/biases\n",
      "tensor_name BN1_3/BN1_3/moving_mean/biased\n",
      "tensor_name BN7/BN7/moving_mean/biased\n",
      "tensor_name BN4_3/moving_mean\n",
      "tensor_name BN1_3/BN1_3/moving_mean/local_step\n",
      "tensor_name conv1_1/weights/Adam\n",
      "tensor_name BN1_3/moving_mean\n",
      "tensor_name BN9/gamma\n",
      "tensor_name conv2_1/weights/Adam_1\n"
     ]
    }
   ],
   "source": [
    "param =[]\n",
    "\n",
    "for key in var_to_shape_map:\n",
    "    print (\"tensor_name\",key)\n",
    "    param.append(reader.get_tensor(key))\n",
    "\n",
    "np.save('dnnout.npy',param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_diff = tf.constant(value=[1, -2, 1],\n",
    "                          dtype=tf.float32,\n",
    "                          shape=[1, 3, 1, 1],\n",
    "                          name=\"diff_intra_2\")\n",
    "\n",
    "image = tf.random_normal([100, 200， 380， 1], mean=-1, stddev=4)\n",
    "\n",
    "output = tf.nn.conv2d(input=image,\n",
    "                      filter=filter_diff,\n",
    "                      strides=[1, 1, 1, 1],\n",
    "                      padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
